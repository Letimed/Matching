data -> extraction + structuration (regates / sql ...) -> données structurées (mais massive) -> netoyage -> visualisation / Stats / Scoring / Ranking / Clustering (regrouper en categorie) -> aide a la décision

+?

problematique


traitement des datas :
	   - Reduction		|
	   - Echantillonnage	|-> hypothèse sur les données (ex : je peux match deux personnes en fonction de leur niveau d'études (combinaison linéaire)) -> echantillon de test (composé de data modifiée				     |	calcule paramettre optimaux (algo) / data non changée -> comparaison -> echantillon de validation avec les data changées -> validée OU retour au traitement de data
	   - Modelisation	|


Algo vu :
Max independent set
min domiting set
max matching (opti quoi qu'il arrive)
set cover
clistering ...
sac a dos
